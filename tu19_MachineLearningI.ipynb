{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c4eb178-7fd5-4a4e-9e27-394a1c7ccc71",
   "metadata": {},
   "source": [
    "# Machine Learning I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5ced89-7be7-43c1-a60f-306b32c98395",
   "metadata": {},
   "source": [
    "Machine learning (ML) is a subfield of artificial intelligence (AI) that focuses on the development of algorithms and models that enable computers to learn and improve their performance on a task without being explicitly programmed. ML relies on training data to identify patterns and relationships, which are then used to make predictions or decisions. The main types of ML are supervised learning, unsupervised learning, and reinforcement learning. Supervised learning involves learning from labeled data, while unsupervised learning identifies patterns in unlabeled data. Reinforcement learning relies on trial and error, with agents learning to perform tasks through a system of rewards and penalties. Applications of ML span numerous industries, including healthcare, finance, marketing, and self-driving cars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45257328-574f-48e8-8c93-c9437736c698",
   "metadata": {},
   "source": [
    "To dip our toes into the world of machine learning, we will use the scikit-learn package (which we've already used for doing regressions). Scikit-learn is an open-source Python library that provides a wide range of machine learning algorithms, tools, and utilities for data analysis and predictive modeling. Built on top of NumPy, SciPy, and Matplotlib, scikit-learn is a versatile and relatively user-friendly package that will allow us to experiment with different machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77728811-682f-4cf4-9c1f-683ce93a29a0",
   "metadata": {},
   "source": [
    "Machine learning is not magic. In fact, we've already used one of the most fundemental machine learning algorithms there is, which is a linear predictor, a.k.a. a linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d763193-bd6d-4e7e-b919-9e59f3e66e06",
   "metadata": {},
   "source": [
    "A plain old linear regression has one of the primary characteristics of all machine learning algorithms, which is that it learns something, in this case a slope and a y-intercept, from the data.\n",
    "\n",
    "All an ordinary regression is missing is one of the other primary characteristics of machine learning algorithms, which is the application to data that was **not** part of the learning process. If a regression can successfully predict data that it has never \"seen\" before, we can be confident that it has learned the correct slope and y-intercept. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b1e329-35ac-424f-91f6-7a4bc6da7340",
   "metadata": {},
   "source": [
    "## Splitting data into *training* and *test* sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2831c7c-6948-436a-bdb7-14636b848455",
   "metadata": {},
   "source": [
    "Machine learning can be described as the process of taking a general algorithm, such as \"there is a linear relationship between median income in a city and the median house price\", into a specific relationship, like $price = a*income + b$, with learned values for $a$ and $b$ that can be used to predict the median house prices for *other* cities - *cities that our algorithm has not encountered before*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c789e2-5055-40dc-a218-f5e1f0590c84",
   "metadata": {},
   "source": [
    "In order to prove our algorithm works, that is, to prove it is good enough to predict or classify new data, we hold back some data in the original data set as \"test\" data. We then teach our algorithm using the remaining \"training\" data. Once our algorithm is trained, we try it out on the test data to see how well it performs on data it has never encountered before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5e7a6d-eeae-4521-b796-ce6c29dda3b0",
   "metadata": {},
   "source": [
    "Put in other words, the idea behind splitting data into test and training sets is to evaluate the performance and generalizability of a machine learning model. This division allows us to train the model on one subset of the data (the training set) and then test its performance on unseen data (the test set). The process helps to ensure that the model is not overfitting and can make accurate predictions when presented with new, unseen data.\n",
    "\n",
    "Here are the key reasons for splitting data into test and training sets:\n",
    "\n",
    "Model evaluation: By testing the model on unseen data, we can evaluate its performance and reliability more objectively. This evaluation helps us understand how well the model generalizes beyond the specific examples it was trained on.\n",
    "\n",
    "Overfitting prevention: Overfitting occurs when a model learns the noise or random fluctuations in the training data, resulting in poor performance on new data. By using a separate test set, we can identify if the model is overfitting and adjust its complexity accordingly.\n",
    "\n",
    "Model selection: In practice, there are often multiple models or algorithms to choose from when solving a particular problem. Splitting the data allows us to compare the performance of different models on the same test set and choose the one that performs best.\n",
    "\n",
    "To ensure a fair evaluation, it's essential to randomly split the data into training and test sets, maintaining the original distribution of the target variable. In practice, the split ratio varies depending on the dataset size and problem domain, with common ratios being 70% training / 30% test or 80% training / 20% test. For smaller datasets, techniques such as cross-validation can be used to make better use of the limited data available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f25523-e557-4d85-bcb4-418b5ff32cd1",
   "metadata": {},
   "source": [
    "## Two machine learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa2cbe6-fbd5-44d6-a6d1-e6d055eabcf0",
   "metadata": {},
   "source": [
    "In this tutorial, we will look at two simple supervised machine learning algorithms, one that predicts *numerical values* of it's targets, and one that predicts the *categories* of the targets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43426c2-7d93-448a-a97d-e0bcb8f5fdb8",
   "metadata": {},
   "source": [
    "The basic workflow for machine learning is:\n",
    "\n",
    "- load the needed things from numpy, matplotlib and, the problem-specific tools from scikit-learn\n",
    "- get the data and wrangle it into shape if necessary\n",
    "- split the data into training and test sets\n",
    "- train the machine learning algorithm\n",
    "- evaluate the performance of the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e3cdf5-6790-44f5-be0f-8714da7fb759",
   "metadata": {},
   "source": [
    "## Linear Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e7497-84a3-4fbb-83ef-f20d198ff5b7",
   "metadata": {},
   "source": [
    "Here, we will revisit the linear regression from a machine learning standpoint. Our specific workflow will be:\n",
    "\n",
    "- import the needed libraries\n",
    "- create a toy data set to play with\n",
    "- split the data into a training set and test set\n",
    "- train (fit) the linear predictor to the training data\n",
    "- see how well the model predicts the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d5da42-e748-455f-9340-172e2bc677fb",
   "metadata": {},
   "source": [
    "Import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b40c6409-e332-4281-93f2-98c7e557066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression              # for simulating data\n",
    "from sklearn.model_selection import train_test_split      # splitting training and test data\n",
    "from sklearn.linear_model import LinearRegression         # making the linear predictor model\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # compute some diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d1f7f-d4fb-4793-9190-66cd77c753c5",
   "metadata": {},
   "source": [
    ">Note: scikit-learn has a LOT of stuff! At least half of the battle is perusing the documentation and figuring out what specific methods you need to use. Once you know what to use, using it is rather easy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0442043c-b7be-4fc7-814b-5cd96d6200a2",
   "metadata": {},
   "source": [
    "Let's create a toy data set for us to play with. (For just one target and one predictor (feature), we could easily use numpy to simulate the data like we have done before, but `make_regression` is *much* easier if we have multiple predictor variables.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "434d6683-c631-4a67-81a6-9bd41603b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic regression dataset\n",
    "n_samples = 100\n",
    "n_features = 1\n",
    "n_targets = 1\n",
    "\n",
    "X, y = make_regression(n_samples=n_samples, n_features=n_features, \n",
    "                       n_targets=n_targets, noise=15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ae5152-80ca-4667-8950-5ecaf89aad25",
   "metadata": {},
   "source": [
    "Our raw data set consists of values in `X` called \"predictors\" and values in `y` called \"targets\". Our goal is to learn the relationship between the predictors and the target, so we can then predict future target values based on any new predictor values. In this case, a regression is what we will use to learn the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5366f18d",
   "metadata": {},
   "source": [
    "> A side note on terminology: Picture a 2D scatterplot – some y values vs. some x values. Laboratory scientists would use the phrases \"dependent variable\" and \"independent variable\" to describe the axes. A statistician might call the the y-axis variable the \"outcome\" and the x-axis values the \"treatment\". In the machine learning world, the terms \"target\" and \"predictor\" are used. Same games, just different names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445b645-d712-4cfa-8788-baa7a0a5c859",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbf7106-ebc4-449f-8afc-778b6a065b9e",
   "metadata": {},
   "source": [
    "Now let's look at our predictor and target data. First let's check their types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec6f73-d814-4735-8751-c7210cd72e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ad7aaa7-b473-4d2c-8783-f94b1635de41",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19231a88-58f3-4242-8707-4a3d8da9ffe1",
   "metadata": {},
   "source": [
    "So they are both numpy ndarrays. Scikit-learn was built on numpy, so numpy arrays are the standard format for data in the scikit-learn world."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c299ba6-f394-4e5a-bb4c-37ecdea24747",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c4dbc-c364-4ab9-bd40-f89566101865",
   "metadata": {},
   "source": [
    "Now let's look at their shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d72b28c-c921-496a-8ed3-4041b38d60c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdc4c5aa-61e0-4f57-9fd4-eb4c33507fc5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d00c1f-ab15-4b3b-bd9b-00bdc3bb181d",
   "metadata": {},
   "source": [
    "So `X` is 2-dimensional and `y` is 1-dimensional. This is because we can and often do have more than 1 predictor, and each predictor goes in a column of `X`, just like we're used to. Most often, however, there is only a single target, so `y` need not have a second dimension. In mathematics (particularly linear algebra and statistics), it is standard to denote matrices with capital letters and vectors with lowercase letters, hence `X` and `y`.\n",
    "\n",
    "*Note: This is the standard data format in machine learning, and the way virtually all scikit-learn methods will be 1) expecting to get data and 2) returning data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5606c63",
   "metadata": {},
   "source": [
    "Now let's split the data into training and test sets using `train_test_split()`, which also allows us to specify some parameters such as the seed of the random number generator in case we need to reproduce the split exactly in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "83fd70d8-59df-48d4-b1d3-6b41f9480b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed92fb-720d-462e-803c-e867ad2f8141",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97388043-94ce-4422-9a87-ce9684b2010a",
   "metadata": {},
   "source": [
    "Use the cell below to examine the shapes of the training and test sets. After doing that, you should be able to figure out what the `test_size` argument to `train_test_split()` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54baad-c6b1-441e-8360-5febd3d366d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "641154b1-46f4-4596-baf7-876fff658a80",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8cb72f-6ef5-4d8d-b3ff-77147849da9d",
   "metadata": {},
   "source": [
    "Now we can make a linear regression object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1fdbbfb8-7345-4666-ad98-c223a939b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression() # too easy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e362cb3-838d-439d-a265-1fbd6dba3fa7",
   "metadata": {},
   "source": [
    "And train it on the training data using its `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e0f65885-3037-403c-aa82-8acf0229fb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61c1b1-c7fc-4c06-b5c3-e9fee3d07915",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72682a8-e80a-4e43-b52d-5bde82f9e2c3",
   "metadata": {},
   "source": [
    "In the cell below, use the `model.<tab>` trick to see what our `model` has to offer. It looks like we can grab the slope (or \"coefficient\" in the lingo), intercept, and generate predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d6d486-7f95-4efa-9038-088c752ad612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77e2654f-135f-40f1-8b9a-d3eb6af99ca8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eebfc22",
   "metadata": {},
   "source": [
    "Let's visually check our fit with a quick scatterplot. First we'll get our predicted target values for the X training values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc8cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703fcdad",
   "metadata": {},
   "source": [
    "Now we can make the actual plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e210891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make scatterplot of the training data and the linear model\n",
    "plt.scatter(X_train, y_train, color='black', label='Training Data')\n",
    "plt.plot(X_train, y_pred, color='blue', linewidth=3, label='Linear Model')\n",
    "plt.title('Training Data and Linear Model')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f63a5df-a486-46ab-859d-d69eb82aa8ea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f7bbd1",
   "metadata": {},
   "source": [
    "Now for the fun part! Let's plot our training data, test data, and predicted values to see how we did! Just re-make the above plot, but add on the test data that we held back in a different color!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db278910-e84f-4251-98a4-628353718b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1db4dc0d-921d-427a-9ac4-3f5926554a8b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fd17e7",
   "metadata": {},
   "source": [
    "Okay, now we can use our model to compute predicted target values at the X values that were held back for training. These will just be the points on the green line above at the x-axis locations of the red data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5526f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d206b",
   "metadata": {},
   "source": [
    "Just to be sure, let's do a quick scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be067d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, y_test, color='red', label='Testing Data')\n",
    "plt.scatter(X_test, y_pred_test, color='green', label='Model Predictions')\n",
    "plt.plot(X_train, y_pred, c='green', label='Regression line')\n",
    "plt.title('Testing Data and Linear Model Predictions')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8322d696",
   "metadata": {},
   "source": [
    "Sure enough, the green points are all in a straight line, and each one shares its x value with one of the red points from the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ede6b-bb4a-46f0-a066-8a649fe447d7",
   "metadata": {},
   "source": [
    "Now let's compute some metrics, like the MSE, $R^2$, and the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc37a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean squared error and R^2 score\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "cor = np.sqrt(r2)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n",
    "print(f\"Correlation: {cor:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560eb96b-14e8-4f15-a7bc-8f928cabd122",
   "metadata": {},
   "source": [
    "The MSE by itself isn't very useful. We know we want it low, but low relative to what? If we had another model to test (like a second order polynomial), then we could compare the two MSEs and favor the model with the lower one.\n",
    "\n",
    "Correlation is another matter, as we know its absolute value has to be between 0 and 1, and the closer to 1 the better. Here we have 0.93, which is quite high, and our predictions are capturing 87% of the variance in the test data (the rest of the variability being random noise). Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e90392f-55b4-4709-a840-95e7cd73732d",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe2196-6b02-47af-9196-40e5d5016ac9",
   "metadata": {},
   "source": [
    "A major use of machine learning is classification - predicting the categories that things belong to based upon measurements of those things. For example, we might want a classifier that can automatically distinguish between benign and malignant tumors based upon measurements of size, shape, etc. done on x-ray images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf512801-a94a-4b00-80cc-037f3b398228",
   "metadata": {},
   "source": [
    "### Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642dbffa-6e7b-473e-8c90-0e258931f49e",
   "metadata": {},
   "source": [
    "The most basic classifier is a \"nearest neighbor\" classifier. In it's simplest form - and this is ridiculously simple - the classifier just stores the locations and labels of the training data. When it gets a new observation to classify, it simply looks to see what observation from the training set is closest, and assigns the new observation the same label.\n",
    "\n",
    "The classifier can be made a little fancier by looking at the nearest 3 or 5 neighbors and going with the majority. For example, in a 3-nearest-neigbor classifier, if 2 of the closest points are of category \"A\" and the 3rd is of category \"B\", the classifier would assign the test point the label \"A\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b17a60-b7ba-4c88-bb30-34ddee511989",
   "metadata": {},
   "source": [
    "Let's try this type of classifier on the famous iris dataset created by Sir Ronald Fisher. This dataset has measurements of the lengths and widths of the petals and sepals for 3 species of iris flowers. Like the titanic, it's a data set that every data science student has to touch at least once!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3341da-ee0e-4934-9f5d-e39ad6fb9c04",
   "metadata": {},
   "source": [
    "You can see a more detailed description of the iris data in the [scikit-learn documentation](https://scikit-learn.org/stable/datasets/toy_dataset.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1950b3-928d-4e48-a5c0-5392d00ab32b",
   "metadata": {},
   "source": [
    "#### Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf854b0-f906-47b0-9a8c-3f33aecf7708",
   "metadata": {},
   "source": [
    "Load our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb0c0d0-f741-4e88-baf1-550a1bac6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010857a6-c993-457a-b013-9f3f9de7f09c",
   "metadata": {},
   "source": [
    "Now we can load the dataset and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16409bb8-13d5-4602-9103-ea0555a0ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c73a427-9f52-434c-8518-92eb3912e51d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9518d8d-dbdd-470e-be54-a428357aea01",
   "metadata": {},
   "source": [
    "Now that we have the data object, let's explore it a little bit. Remember the \\<tab\\> trick!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218db28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85ace7e5-37f2-409e-9eba-bbcfea16414b",
   "metadata": {},
   "source": [
    "Notice in particular that `iris.target` contains a \"dummy\" variable that codes the species with numbers. This is very common, although sometimes we want to convert these back to the actual names, as we do below for plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457bbe2-5c4b-4d12-a481-6736217e09c6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd88e69-3af0-474a-9a5d-2783140e72cd",
   "metadata": {},
   "source": [
    "##### Make machine learning format data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72094bbe",
   "metadata": {},
   "source": [
    "This is our first job, but it's pretty easy because `iris.data` is already a matrix, and `iris.target` is already a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46523951-f577-4772-af9f-8d2c657b687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data     # predictor matrix\n",
    "y = iris.target   # target vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd9e077-9922-438f-9227-7d0174f90e54",
   "metadata": {},
   "source": [
    "#### Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc905619-cdb2-4f61-8fd7-0741973bb24a",
   "metadata": {},
   "source": [
    "This is where pandas and seaborn come in handy! The code below should all look familiar, except for the `Categorical.from_codes()` method that lets us make a column of species names from the codes in the target vector. If you didn't look at what `iris.target_names` is above, take a second to do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc73c3ab-d7c3-4db8-b382-e81a6d14d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas DataFrame from the dataset\n",
    "df = pd.DataFrame(X, columns = iris.feature_names)\n",
    "\n",
    "# Add the target column to the DataFrame as actual names\n",
    "df['species'] = pd.Categorical.from_codes(y, iris.target_names)\n",
    "\n",
    "# Create a scatterplot matrix using seaborn's pairplot()\n",
    "sns.pairplot(df, hue='species', markers=[\"o\", \"s\", \"d\"])\n",
    "plt.suptitle(\"Scatterplot Matrix of Iris Dataset\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f03c0e4-9e91-497a-bfd3-cb154a5a6070",
   "metadata": {},
   "source": [
    "Take a minute to ponder this figure. If you had to pick 2 variables to use to separate the species, which ones would you pick?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097fcc0b-1b4f-4500-ab1a-7e60979b312a",
   "metadata": {},
   "source": [
    "For illustration purposes, we'll use the first two (sepal length and width), though this clearly wouldn't be the best choice. But it should give us some mistakes (misclassifications) to look at!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3affb48a-f479-48a1-b22a-3020c2559bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, :2]  # Use only the first two features (sepal length and sepal width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba305d07-5ddb-49cf-9016-b2d16d0e113d",
   "metadata": {},
   "source": [
    "Now lets make a scatterplot of the data we're going to use. This should look like the plot in the second row of the first column, above. \n",
    "\n",
    "If you're feeling sharp, you can write your own code instead of using the code below! You don't have to get fancy, but make sure the species are distinguished by either color or symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c2b6c6-cc85-4f14-a16b-0b647d8fbb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of the first two features with color indicating category\n",
    "colors = ['red', 'green', 'blue']\n",
    "species = iris.target_names\n",
    "\n",
    "for i, color, target_name in zip(range(3), colors, species):\n",
    "    plt.scatter(X[y == i, 0], X[y == i, 1], \n",
    "                color=color, label=target_name, alpha = 0.4)\n",
    "\n",
    "plt.xlabel(iris.feature_names[0])  # Sepal length\n",
    "plt.ylabel(iris.feature_names[1])  # Sepal width\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Iris dataset: Sepal length vs. Sepal width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d386d4-dcb0-4884-bc3f-280f4b635d41",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c840d5ed-a6bc-4151-9f1d-cd4ef9b581b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Splitting into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263c1fff-887c-46c4-a320-3f98ecbb74dc",
   "metadata": {},
   "source": [
    "In the cell below, split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aab7de-4c10-40ee-80d7-bb0de8d68ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50c96ff2-dfbd-4bb4-9fd1-a7d91ce5ee47",
   "metadata": {},
   "source": [
    "Look at the shapes of training and test data. Do they make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d5ca5-584b-42e4-bdee-df28fd61f98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8319cce0-11bd-4317-9aa5-02bd8024c328",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11020c06-9c24-453d-9f85-bf9e76991f3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create and train the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3cfdc8-e61b-4d57-9be9-d7103d98c61e",
   "metadata": {},
   "source": [
    "Now we can create the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6720cbfa-f67a-4fbb-ad47-1c2e3b5df910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create the K-Nearest Neighbors classifier with k=3\n",
    "k = 3\n",
    "knn = KNeighborsClassifier(n_neighbors=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ac551-3d89-4f60-80f7-a472cadc1e36",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82813230-dc1b-4922-a99b-8d304dc4898c",
   "metadata": {},
   "source": [
    "In the cell below, train our classifier using using the `fit()` method, just like with the regression model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea377830-382a-4fa7-97f1-964e875fdbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a17f059-de42-48f8-ac2f-33349040f6a5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d090d7b9-78a2-44a1-a560-02bdd0c11b39",
   "metadata": {},
   "source": [
    "#### Predicting the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5367907a-5780-45a4-a01e-d75ffe291587",
   "metadata": {},
   "source": [
    "In the cell below, generate the predicted values from our classifier and put them in a variable called `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4b7cca-277b-4dd9-8112-8d083a4d3954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e78ffe6-197e-4bc3-af59-6c994378ea34",
   "metadata": {},
   "source": [
    "Look at the shape of `y_pred` – it should match the shape of `y_test`, which holds the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de08539-44a3-44bb-8228-067d0764cfaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1ec788b-03f9-4fc7-b237-f15b66ea18a0",
   "metadata": {},
   "source": [
    "In the cell below, see if you can come up with a quick way to see how we did by comparing `y_pred` and `y_test`. Remember, there are only 3 possible target values (0, 1, 2) and they either match at any given location in `y_pred` and `y_test`, or they don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f24e28-4560-4e83-8e49-d60dc26a987f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c283661-f1d0-4728-9d80-33e76f1a4d2c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bb81df-8ec4-4ba8-ac00-8024b108d64b",
   "metadata": {},
   "source": [
    "Now let's make a plot of our predicted values. Just recycle the code from above substituting `X_test` for `X` and `y_pred` for `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84684c2f-59e3-42d9-b2a6-a9df8a2312ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, color, target_name in zip(range(3), colors, species):\n",
    "    plt.scatter(X_test[y_pred == i, 0], X_test[y_pred == i, 1], \n",
    "                color=color, label=target_name, alpha = 0.4)\n",
    "\n",
    "plt.xlabel(iris.feature_names[0])  # Sepal length\n",
    "plt.ylabel(iris.feature_names[1])  # Sepal width\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Iris dataset: Sepal length vs. Sepal width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f6a3bd-f61d-4cb9-b7b8-74acda2dc79f",
   "metadata": {},
   "source": [
    "Does this look reasonable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dde4c5-7833-4659-a75e-f9b8e3d84e9f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "377615b9-b94c-4f24-a75b-5b842d07ca87",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649017ef-dfd0-4066-8e65-f8fb5e2226b6",
   "metadata": {},
   "source": [
    "Let's plot the predicted and test values on the same graph. We can offset the predicted and true points a little tiny bit so we can see where the mistakes are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d869c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0.05 # small offset to see both sets of values\n",
    "\n",
    "for i, color, target_name in zip(range(3), colors, species):\n",
    "    plt.scatter(X_test[y_pred == i, 0], X_test[y_pred == i, 1], \n",
    "                color=color, label=target_name+\" pred\", alpha = 0.4)\n",
    "    plt.scatter(X_test[y_test == i, 0]+offset, X_test[y_test == i, 1], \n",
    "                color=color, marker = 's', label=target_name+\" test\", alpha = 0.4)\n",
    "\n",
    "plt.xlabel(iris.feature_names[0])  # Sepal length\n",
    "plt.ylabel(iris.feature_names[1])  # Sepal width\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Iris dataset: Sepal length vs. Sepal width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d600d3",
   "metadata": {},
   "source": [
    "So everywhere the colors match, our classification was correct; where there's a mismatch, it wasn't. It looks like \"setosa\" was categorized perfectly, but there were some mismatches with the other two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7100ee5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade44d9-0489-4439-a2dd-e1afe33a980b",
   "metadata": {},
   "source": [
    "#### Performance Metrics for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b68dff8-e83e-41e2-8d07-e88c642afadc",
   "metadata": {},
   "source": [
    "The scikit-learn package provides a few ways to assess the performance of classifier by comparing the true (test) values with the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c441f5-5ff9-40e2-8ec4-3780ef0da381",
   "metadata": {},
   "source": [
    "The simplest of these is the accuracy score, which you may have come up with yourself above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462d641-a810-4763-9ee3-6284def726f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy Score: {acc_score:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f43f4d-135e-44c1-a48f-c9b87d4ea745",
   "metadata": {},
   "source": [
    "Next, we can look at the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7938a6fa-c35c-48a9-81db-e3e9a7440624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(species)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da1cc0-15e0-4a96-b949-31387b8c4c16",
   "metadata": {},
   "source": [
    "In this matrix, the true labels are the rows and the predicted labels are the columns. Each cell entry shows how many observations had the corresponding true and predicted label. The entries along the diagonal are thus all correct. The off diagonals are the errors, and we can see that 5 examples of virginica were labeled as \"versicolor\", and 6 errors were made for these same 2 species in the other direction for 11 total errors in all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d20e687-0bba-4281-9470-4395988b0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cls_report = classification_report(y_test, y_pred)\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc507c-c6cd-414d-9242-d329dc3a1c0e",
   "metadata": {},
   "source": [
    "The classification_report function provides a summary of a classifier's performance in terms of various evaluation metrics. The upper part of the table includes the \"precision\", \"recall\", \"F1-score\", and support for each class (\"support\" is the fancy machine-learning word for \"sample size\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1910a912-59e2-4055-ba66-f2a6409f5ec5",
   "metadata": {},
   "source": [
    "*Precision*: Precision is the ratio of true positive predictions to the sum of true positive and false positive predictions. It measures the classifier's ability to correctly identify positive instances out of all instances predicted as positive. A high precision indicates a low false positive rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd61a0-cf33-443c-94fc-0ed3e3c2107c",
   "metadata": {},
   "source": [
    "For *virginica*, this would be the number of times *virginica* was correctly indentified divided by the total number of times *any* flower was identified as *virginica*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a5b279-f986-4d68-8ceb-e975c1234bf5",
   "metadata": {},
   "source": [
    "In the cell below, compute this \"by hand\" from the values in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b1693-b29e-4391-8fad-0f7d6d558731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08bb8967-1402-4431-b19b-3c0878a46c9d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a2ca1-6afe-4a2e-b77b-d7a32872d5bb",
   "metadata": {},
   "source": [
    "*Recall (Sensitivity)*: Recall is the ratio of true positive predictions to the sum of true positive and false negative predictions. It measures the classifier's ability to identify all the positive instances. A high recall indicates a low false negative rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ecd5f4-c11a-48ad-b14a-ae752bf417d5",
   "metadata": {},
   "source": [
    "For *virginica*, this would be the number of times *virginica* was correctly indentified divided by the total number of *virginica* flowers in the sample:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc005b9-3644-47a0-91f7-0391316f7678",
   "metadata": {},
   "source": [
    "In the cell below, compute this \"by hand\" from the values in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0881c1-88ec-4c1c-8b5d-af5c545aadd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e80339e4-b4a8-4e0c-a36d-b1daae7ae2c3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e34aa-c9be-4a93-8bdf-97108ab52c21",
   "metadata": {},
   "source": [
    "F1-score: The F1-score is the harmonic mean of precision and recall, and it provides a single value that balances both metrics. It ranges from 0 (worst) to 1 (best), with a higher F1-score indicating better overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d0b02-75b2-4608-a6cf-9aa4bb966af9",
   "metadata": {},
   "source": [
    "For *virginica*, this would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596fe90-0be6-4947-ab8a-ae314f8cd497",
   "metadata": {},
   "outputs": [],
   "source": [
    "2/((1/0.57)+(1/0.62))  # compute harmonic mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717f2ae4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671dff78-1937-4bda-83ef-fb70bd0106b9",
   "metadata": {},
   "source": [
    "*Support*: Support is just the number of actual occurrences of each class in the dataset. It helps interpret the results of the other metrics by providing context about the class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a1fabc-7f6f-496e-98c2-660b766d7425",
   "metadata": {},
   "source": [
    "*Accuracy*: Proportion of correctly labeled observations - the same as computed by `accuracy_score()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b414448a-2b55-4988-aa7a-c6a31f04807d",
   "metadata": {},
   "source": [
    "The classification report also provides macro and weighted averages for the precision, recall, and F1-score:\n",
    "\n",
    "*Macro Average*: The macro average computes the arithmetic mean of the metric scores for each class, without considering the class distribution. It treats all classes equally, which may not be ideal for imbalanced datasets.\n",
    "\n",
    "*Weighted Average*: The weighted average computes the average of the metric scores for each class, weighted by the support of each class. This approach accounts for class imbalance and provides a more representative overall performance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f97d9db",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65ac6d7-0fcb-4382-b503-5cc0bde27e2c",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50f922f-5178-47ef-93f5-99e4cf88dc6c",
   "metadata": {},
   "source": [
    "In this tutorial, we have looked at two basic machine learning algorithms:\n",
    "\n",
    "- a linear predictor that estimates numberical target values\n",
    "- a nearest neighbor classifier that predicts target categories\n",
    "\n",
    "These techniques are not mysterious. The both start with a general algorithm, use training data to tune the general algorithm into a problem-specific one, and then use this to predict targets from novel predictor data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede73e52-c15c-49af-9390-d515ab4422d9",
   "metadata": {},
   "source": [
    "In the next tutorial, we'll look at some more sophisticated categorization algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
