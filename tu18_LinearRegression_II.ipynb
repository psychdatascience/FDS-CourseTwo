{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ea9ad2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2d5b259",
   "metadata": {},
   "source": [
    "---\n",
    "### Getting more technical (THRUSDAY)\n",
    "\n",
    "talk about "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a30b22",
   "metadata": {},
   "source": [
    "Define:\n",
    "- Mean Squared Errors\n",
    "- residuals\n",
    "- total sum of error\n",
    "- R2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009607c0",
   "metadata": {},
   "source": [
    "#### Mean Squared Error (MSE)\n",
    "\n",
    "MSE stands for Mean Squared Error, which is a widely used loss function for regression problems. It measures the average squared difference between the predicted and actual values. Here's the formula for MSE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1680f62a",
   "metadata": {},
   "source": [
    "$MSE = 1/n * ∑(y - ŷ)²$\n",
    "\n",
    "where:\n",
    "\n",
    "  - $n$ is the number of observations\n",
    "  - $y$ is the actual value\n",
    "  - $ŷ$ is the predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62263d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(123)\n",
    "x = np.random.rand(50)\n",
    "y = 2*x + 0.5*np.random.randn(50)\n",
    "\n",
    "# Fit a linear regression model\n",
    "coeffs = np.polyfit(x, y, 1)\n",
    "y_pred = np.polyval(coeffs, x)\n",
    "\n",
    "# Compute MSE\n",
    "mse = np.mean((y - y_pred)**2)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be61c4f0",
   "metadata": {},
   "source": [
    "The MSE reports the average squared difference between the predicted and actual values. \n",
    "\n",
    "The MSE is use to fit models and evaluate models.\n",
    "\n",
    "Below, we plot the data and the regression line using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d864db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data and the regression line\n",
    "plt.scatter(x, y, label='Data')\n",
    "plt.plot(x, y_pred, color='r', label='Linear regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd80cc3",
   "metadata": {},
   "source": [
    "#### Residuals\n",
    "\n",
    "Residuals are the differences between the actual values of the dependent variable and the predicted values of the dependent variable. \n",
    "\n",
    "In the context of MSE, the residuals are the differences between the observed values y and the predicted values ŷ. Residuals are useful for evaluating the performance of the model and checking for patterns or trends that the model may have missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5cd386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(123)\n",
    "x = np.random.rand(50)\n",
    "y = 2*x + 0.5*np.random.randn(50)\n",
    "\n",
    "# Fit a linear regression model\n",
    "coeffs = np.polyfit(x, y, 1)\n",
    "y_pred = np.polyval(coeffs, x)\n",
    "\n",
    "# Compute residuals\n",
    "residuals = y - y_pred\n",
    "print(\"Residuals:\", residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b09a148",
   "metadata": {},
   "source": [
    "In this example, we first generate some random data using NumPy. Then, we fit a linear regression model using the np.polyfit function and make predictions on the input data using the np.polyval function. Finally, we compute the residuals as the difference between the actual values of y and the predicted values ŷ. The residuals are printed to the console.\n",
    "\n",
    "After model fitting, it is important to examine the residuals to ensure that they are randomly distributed around zero and do not exhibit any patterns or trends. One way to visualize the residuals is to create a scatter plot of the residuals against the predicted values. If the residuals are randomly distributed around zero, the plot should not exhibit any patterns or trends. If there is a pattern or trend, it suggests that the model is not capturing some aspect of the data and may need to be adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b461e060",
   "metadata": {},
   "source": [
    "This code creates a scatter plot of the residuals against the predicted values, with a red line at y=0 to indicate where the residuals should be centered around. A well-fitted model should have a scatter plot of residuals that is relatively evenly distributed around the red line. If there are any patterns or trends, this may indicate that the model is not capturing some aspect of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf47c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create scatter plot of residuals\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0559c5",
   "metadata": {},
   "source": [
    "### Linear regression using scikit-learn (generalized linear regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7692dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df229dd0",
   "metadata": {},
   "source": [
    "Next, we need to create some sample data to work with. Let's say we want to establish a relationship between the number of hours studied and the grades obtained by students. We can create a NumPy array with some random data like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20]).reshape((-1, 1))\n",
    "y = np.array([60, 80, 90, 92, 94, 94, 96, 98, 98, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb80b88",
   "metadata": {},
   "source": [
    "Here, we've created two NumPy arrays: x, which contains the number of hours studied, and y, which contains the corresponding grades obtained by the students.\n",
    "\n",
    "Now, we can create a LinearRegression object and fit our data to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f75b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bff365",
   "metadata": {},
   "source": [
    "This created a linear regression model and fit it to our data.\n",
    "\n",
    "We can now use the predict() method of our model to make predictions for new data points. For example, if we want to predict the grades of students who have studied for 15 hours, we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc13bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = np.array([15]).reshape((-1, 1))\n",
    "y_new = model.predict(x_new)\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8993a34",
   "metadata": {},
   "source": [
    "The above outputted the predicted grade for a student who has studied for 15 hours.\n",
    "\n",
    "We can also plot our data and the linear regression line to visualize the relationship between the two variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7c4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230374c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myR2(y,y_hat):\n",
    "    # Calculate R-squared\n",
    "    residuals = y - y_hat\n",
    "\n",
    "    ss_res = np.sum(residuals**2)\n",
    "    ss_tot = np.sum((y - np.mean(y))**2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    print(r_squared)\n",
    "    \n",
    "    return r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34bf080",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = myR2(y,y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61503c43",
   "metadata": {},
   "source": [
    "In the code above, we first generate some random data and fit a linear regression model to it using polyfit from NumPy.\n",
    "\n",
    "We then calculate the residuals of the model, the sum of squares of the residuals (ss_res), and the total sum of squares (ss_tot) of the data.\n",
    "\n",
    "Finally, we calculate the R-squared (R²) value using the formula 1 - (ss_res / ss_tot).\n",
    "\n",
    "R-squared (R²) is a statistical measure that represents the proportion of variance in the dependent variable (y) that is explained by the independent variable(s) (x) in a linear regression model. In other words, it measures how well the observed data points fit the regression line.\n",
    "\n",
    "R-squared values range from 0 to 1, where a value of 0 indicates that the model does not explain any of the variation in the dependent variable and a value of 1 indicates that the model explains all of the variation in the dependent variable.\n",
    "\n",
    "An R-squared value of 0.8, for example, indicates that 80% of the variation in the dependent variable is explained by the independent variable(s) in the model. R-squared is commonly used as a goodness-of-fit measure to evaluate how well a linear regression model fits the data.\n",
    "\n",
    "Our R-squared (R²) was OK in this case not too good not too bad. We will discuss more about R², sum of squares, etc.\n",
    "\n",
    "Before we do that, let's think about good and bad models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
