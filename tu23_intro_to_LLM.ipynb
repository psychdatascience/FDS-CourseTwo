{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8402e06e",
   "metadata": {},
   "source": [
    "# Introduction to Large Language Models and Artificial Intelligence\n",
    "\n",
    "\n",
    "#### Learning goals\n",
    " * fundamental concepts about artificial intelligence (AI)\n",
    " * taxonomy of AI models\n",
    " * trasformers and large language models (LLM)\n",
    " * API calls to ChatGPT\n",
    " \n",
    " \n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e1b364",
   "metadata": {},
   "source": [
    "AI, or artificial intelligence, refers to the development of software (code) and hardware (robots) systems that can perform tasks that are typically performed by humans. Example tasks vary enormously and can span, writing meanigful emails to co-workers, writing Python code to analyze data provided to ou by your company, or identifying and selecting fruits that are over-ripen and must be discarded in a supermarket shelf. Today, we believe humans are necessary for most of these tasks, yet humans have been working for years to develop machines that can perform their own tasks so as to leaving humans with more spare time to spend with their friends, families.\n",
    "\n",
    "Most of these tasks comprise complex operations that include learning, reasoning, problem-solving, perception, understanding natural language, and more. Some of these taks tha tinvolve physical interactions with the natural environment require human-like physical abilities and for these resons Humanoids (robot looking like humans) are being developed. These tasks (or at least some of them) are believed to require human-like abilities and intelligence.\n",
    "\n",
    "In a more theoretic sense, AI aims to create machines that can mimic cognitive functions associated with human minds.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd51bea",
   "metadata": {},
   "source": [
    "AI recently become a main news topic because of a recent breakthrough in both software and hardaware. [This is a neat video about AI](https://www.youtube.com/watch?v=aZ5EsdnpLMI&ab_channel=60Minutes). After years of development, we have now humanoids that can perform advanced mobility tasks and that look like humans. [This is a short video describing a few of these humanoids being developed](https://www.youtube.com/watch?v=6UW05Hq-1s8&ab_channel=Xplained). At the same time software has been developed and embedded into a variety of systems that can perform tasks that humans \n",
    "\n",
    "The field of Ai is large and expansive and this tutorial is not the place for an exhaustive discussion of AI. Instead, we will focus on a specific sub-field of AI (generative AI) and more specifically on Large-Language Models (LLMs) and even more specifically ChatGPT the system developed and made available to many by the company OpenAI.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926a603",
   "metadata": {},
   "source": [
    "## Types of AI\n",
    "\n",
    " The field of AI comprises of many types of systems. In broad strokes though, we can simplify the types of AI into two main types. **Traditional AI** (a.k.a., weak AI) and **Generative AI**. [See this short article from the U.S. Chambers of Commerce](https://www.uschamber.com/co/run/technology/traditional-ai-vs-generative-ai). In a nutshell, Traditional and Generative AI represent two different paradigms within the field of artificial intelligence, each with its own approach to solving problems and generating intelligent behavior.\n",
    "\n",
    "Before we look at how these two types of AI might work let's put AI into the broader context.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ad94f",
   "metadata": {},
   "source": [
    "AI is part of a large set of work that comprises many sub-discipline, models and an algorithms. Below is a short list of the few types of concepts that are helpful to understand AI.\n",
    "\n",
    "**Machine Learning**: Machine learning is a subset of AI that focuses on developing algorithms and techniques that allow computers to learn from data and make predictions or decisions without being explicitly programmed. Machine learning algorithms can improve their performance over time as they are exposed to more data.\n",
    "\n",
    "**Deep Learning**: Deep learning is a subfield of machine learning that involves neural networks with many layers (hence the term \"deep\"). Deep learning algorithms have demonstrated remarkable success in tasks such as image recognition, natural language processing, and speech recognition.\n",
    "\n",
    "**Natural Language Processing (NLP)**: NLP is a branch of AI that focuses on enabling computers to understand, interpret, and generate human language. NLP techniques are used in applications such as chatbots, language translation, sentiment analysis, and text summarization.\n",
    "\n",
    "**Computer Vision**: Computer vision is another subfield of AI concerned with enabling computers to interpret and understand visual information from the real world. Computer vision algorithms can analyze images and videos, detect objects and patterns, and make decisions based on visual input.\n",
    "\n",
    "**Robotics**: Robotics combines elements of AI, machine learning, and mechanical engineering to design and develop robots that can perform tasks autonomously or semi-autonomously. Robots equipped with AI capabilities can navigate their environments, manipulate objects, and interact with humans and other robots.\n",
    "\n",
    "**Expert Systems**: Expert systems are AI systems that emulate the decision-making ability of a human expert in a specific domain. They use a knowledge base of facts and rules to provide advice or solve problems within their area of expertise.\n",
    "\n",
    "**Reinforcement Learning**: Reinforcement learning is a type of machine learning where an agent learns to make decisions by interacting with an environment. The agent receives feedback in the form of rewards or penalties based on its actions, allowing it to learn optimal behavior through trial and error.\n",
    "\n",
    "Overall, AI encompasses a broad range of techniques, algorithms, and applications aimed at creating intelligent machines capable of performing tasks that would typically require human intelligence. Its potential impact spans across various industries, including healthcare, finance, transportation, entertainment, and beyond.\n",
    "\n",
    "Below we will look at one example of Traditional and Generative AI to get a basic sense of how they work.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b9efb",
   "metadata": {},
   "source": [
    "### Example of how Traditional and Generative AI solve problems\n",
    "\n",
    "Traditional AI and generative AI represent different approaches to solving problems. Traditional AI typically relies on rule-based systems, expert knowledge, and explicit programming to solve tasks. Generative AI focuses on generating data or content based on learned patterns and probabilistic models. \n",
    "\n",
    "The example sudo-code illustrates the difference between the two approaches using a simple problem: Generating text responses to user queries.\n",
    "\n",
    "This will be our Problem Statement: Given a set of predefined responses, generate an appropriate response to a user query about the weather.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdffd25",
   "metadata": {},
   "source": [
    "#### Traditional AI Pseudo Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc24d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd1373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traditional_ai(query):\n",
    "    if \"weather\" in query:\n",
    "        return \"The weather is currently sunny.\"\n",
    "    elif \"rain\" in query:\n",
    "        return \"Yes, it's raining today.\"\n",
    "    elif \"temperature\" in query:\n",
    "        return \"The temperature is 25 degrees Celsius.\"\n",
    "    else:\n",
    "        return \"I'm sorry, I don't understand your query.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e748e2",
   "metadata": {},
   "source": [
    "As we can see in the example code, Traditional AI, the responses are predetermined based on specific keywords or patterns in the user query. The system follows predefined rules to select an appropriate response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0721e18",
   "metadata": {},
   "source": [
    "#### Generative AI Pseudo Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a47fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note. The code below is not expected to work. \n",
    "# So do not attempt running it\n",
    "import openai\n",
    "\n",
    "def generative_ai(query):\n",
    "    prompt = \"User: \" + query + \"\\nAI:\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d6139",
   "metadata": {},
   "source": [
    "In generative AI, we use a language model (such as GPT) to generate responses based on the input query. What we are doing in the code above is to call a \"trained model\" a neural network that had learned already from other texts written by others (mostly written by humans) and that we can use by calling using different initial queries. The model has been trained on a vast amount of text data and can generate contextually appropriate responses. \n",
    "\n",
    "Whereas in Traditional AI we write code to solve a problem (we write the problek solution in the code), in Generative AI we load a model to solve a problem. We do not have two write the solution explicitly but instead we ask a trained model to provide the solution for us, so we implicitly ask the AI model to ansker for us.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfca1ff",
   "metadata": {},
   "source": [
    "#### Example Usage:\n",
    "\n",
    "After writing the code, we will then set up code to receive an input query, or the question, from a user and pass it to the function defined above. \n",
    "\n",
    "Below is a (non-working) example of how we would receive a query and call the Traditional or Generative AI response:\n",
    "\n",
    "The code is not in a `code cell` because it will not work for the time being, that is OK. Read it and try to grasp the logic for the time being:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5ca47d",
   "metadata": {},
   "source": [
    "```\n",
    "query = \"What's the weather like today?\"\n",
    "traditional_response = traditional_ai(query)\n",
    "generative_response = generative_ai(query)\n",
    "\n",
    "print(\"Traditional AI Response:\", traditional_response)\n",
    "print(\"Generative AI Response:\", generative_response)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0b5c32",
   "metadata": {},
   "source": [
    "### Transformers\n",
    "\n",
    "The sudo-code above and the code we will learn about below focuses on a specifci class of AI systems; *Transformers.* Transformers are Deep Learning systems that uses Natural Language Processing (NLP). When a transformer is large (i.e., it has been trained on many, many, may examples of text written by humans) it is referred to as a Large-Language Model (LLM). \n",
    "\n",
    "A transformer is a powerful tool in the world of AI that helps computers understand and process human language. Transformers help computers break down that long sentences into smaller parts (tokens), figuring out which words are related to each other and how they fit together. \n",
    "\n",
    "A transformer is like a super-smart student in a classroom, capable of paying attention to different parts of a text at the same time. Instead of reading a sentence from start to finish, transformers can focus on important words and relationships between them, just like how a student might focus on key concepts in a lesson. This ability allows transformers to handle complex language tasks, such as translation and summarization, with impressive accuracy and efficiency, making them a game-changer in the field of natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac9d196",
   "metadata": {},
   "source": [
    "Soon we will attempt to use a Generative AI system properly, more specifically we will use a transformer. Before we do that we need to learn a few more concepts.\n",
    "\n",
    "**What is a GPT:** \n",
    "\n",
    "Generative Pre-trained Transformer (GPT) is a series of transformer-based language models developed by OpenAI. GPT models are designed for natural language understanding and generation tasks, including text completion, question answering, summarization, translation, and more. \n",
    "\n",
    "The key characteristics of GPT models include:\n",
    "\n",
    "*Pre-training:* GPT models are pre-trained on vast amounts of text data from diverse sources, such as books, articles, websites, and other textual sources. During pre-training, the model learns to predict the next word in a sequence based on the preceding context. This process enables the model to capture rich semantic information and linguistic patterns from the training data.\n",
    "\n",
    "*Generative Capability:* GPT models are generative in nature, meaning they can generate human-like text based on a given prompt or context. Given an input prompt, the model generates a continuation of text that is coherent and contextually relevant, drawing upon its knowledge of language acquired during pre-training.\n",
    "\n",
    "*Fine-tuning:* While GPT models are initially pre-trained on a large corpus of text data, they can be further fine-tuned on task-specific datasets to adapt their knowledge and capabilities to specific applications. Fine-tuning allows GPT models to achieve state-of-the-art performance on various NLP tasks, including sentiment analysis, text classification, and language translation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e4ab91",
   "metadata": {},
   "source": [
    "#### Anatomy of a basic Generative AI code\n",
    "\n",
    "In the Generative AI Pseudo-code presented above, we can notice the use a few important keywords:\n",
    "\n",
    "- Prompt\n",
    "- Query\n",
    "- Response\n",
    "- Tokens\n",
    "\n",
    "These are important terms to become familiar with as they are key to understanding how to write code that uses Generative AI models. Below is a very short introduction to these terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4fa31e",
   "metadata": {},
   "source": [
    "Generative AI code utilizes standard concepts that are used to set up, call and utilize the pre-trained LLM:\n",
    "\n",
    "**Prompt:**\n",
    "A prompt is a piece of text provided as input to a generative LLM to elicit a specific response. It serves as the initial context or instruction for the model to generate text. The prompt typically contains some initial information or a question that guides the LLM in generating a coherent and relevant response. It can be tailored to the specific task or application, providing context and constraints for the generated text. In code writing, a prompt could be a partial code snippet or a description of a programming problem, instructing the LLM to generate the remaining code or a solution. For example, a prompt might be \"Write a function that takes two numbers as input and returns their sum.\"\n",
    "\n",
    "**Query:**\n",
    "A query refers to a request or question posed to the generative LLM, typically in the form of text input. Queries are used to solicit responses from the LLM based on specific information or instructions provided by the user. In code writing tasks, a query could be a programming-related question or a problem statement, prompting the LLM to generate code snippets or solutions. For instance, a query might be \"Implement a function to sort an array of integers in ascending order.\"\n",
    "\n",
    "**Response:**\n",
    "A response is the output generated by the generative LLM in reaction to a given prompt or query. It represents the text or code generated by the model. Responses provide answers, solutions, or generated text based on the input provided to the LLM. The quality and relevance of the response depend on the model's training data, architecture, and parameters. In code writing tasks, a response could be a complete code snippet generated by the LLM based on the prompt or query. For instance, if the prompt is \"Write a Python function to calculate the factorial of a number,\" the response might be the corresponding Python code for factorial calculation.\n",
    "\n",
    "**Tokens:**\n",
    "Tokens are the smallest units of text or code that the generative LLM processes and generates. Tokens can represent words, subwords, or characters depending on the tokenization strategy used. Tokens serve as the building blocks of text generation and understanding in LLMs. They enable the model to capture semantic meaning, syntax, and structure of the input and generated text. In code writing tasks, tokens could represent individual programming keywords, identifiers, operators, or punctuation symbols. For instance, in Python code, tokens could include words like \"def\" (for defining functions), \"if\" (for conditional statements), and \"return\" (for returning values), as well as variable names and numeric literals.\n",
    "\n",
    "As an overview, prompts provide initial context or instructions, queries solicit specific responses, responses are the generated output, and tokens represent the smallest units of text or code processed by the LLM. These concepts are fundamental to leveraging generative LLMs for various text generation tasks, including code writing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edfd8e9",
   "metadata": {},
   "source": [
    "### APIs, Prompts and Tokens\n",
    "\n",
    "Prompts and Tokens are perhaps the most interesting and complex concepts. It has been show that writing useful Prompts can really improve the Responses of the AI systems to the users' Queries. Writing prompts is generally referred to as Prompt Engineering.\n",
    "\n",
    "##### Prompts and Prompt Engineering:\n",
    "Prompt engineering refers to the process of crafting effective prompts for language models, particularly generative language models like GPT. It involves designing input text that guides the model to produce desired outputs or behaviors. Prompt engineering is essential for controlling and directing the output of language models, ensuring that they generate responses that are relevant, accurate, and aligned with the user's intent.\n",
    "\n",
    "##### Tokens and Tokenization:\n",
    "Tokenization is the process of breaking down a piece of text into smaller units, called tokens. These tokens can be words, subwords, characters, or other linguistic units, depending on the specific tokenization strategy used. Tokenization is a fundamental preprocessing step in natural language processing (NLP) and text mining tasks, enabling machines to understand and process human language effectively.\n",
    "\n",
    "##### Application programming Interface (API):\n",
    "An API, or Application Programming Interface, is a set of rules, protocols, and tools that allows different software applications to communicate and interact with each other. It defines how different components of software systems should interact, enabling developers to access and use the functionality of other software components, services, or platforms without needing to understand their internal workings. APIs facilitate the exchange of data and resources between applications, enabling the creation of integrated and interconnected software solutions.\n",
    "\n",
    "As an analogy, imagine you're in a restaurant. You (the client) sit at a table and want to order food from the kitchen (the server). You don't go into the kitchen and start cooking yourself; instead, you communicate your order to the waiter (the API), who then conveys it to the kitchen on your behalf.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c050ff2",
   "metadata": {},
   "source": [
    "#### Tokenization example\n",
    "\n",
    "Let's first think a bit deeper about Tokenization. Below is example Python code that demonstrates tokenization using the method `.split()`, which is a built-in method for strings. This method splits a string into a list of substrings based on a specified separator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input text\n",
    "input_text = \"Tokenization is the process of splitting text into tokens.\"\n",
    "\n",
    "# Tokenization using split() method\n",
    "tokens = input_text.split()\n",
    "\n",
    "# Display tokens\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7858cde",
   "metadata": {},
   "source": [
    "In this example, we have an input text `\"Tokenization is the process of splitting text into tokens.\"` and \n",
    "we use the `split()` without specifying any separator. By default, `split()` splits the text based on the *whitespace* characters (spaces, tabs, newline characters). The resulting tokens list contains the individual words \"tokenized\" from the input text.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb95409",
   "metadata": {},
   "source": [
    "There are more advanced tokenization libraries available, such as `NLTK` (Natural Language Toolkit) or `spaCy`, that are more commonly used for AI models. Yet, the fundamental concepts is the same as demonstrated using `split()`. \n",
    "\n",
    "The above is an example of Word Tokenization. Yet, tokenization can focus on subwords, or even characters and importantly to groups of words that go together in a sentence. For example, *for example* could be used as a token as it often comes together at the beginning of a sentence.\n",
    "\n",
    "Overall, tokenization plays a crucial role in NLP tasks by converting raw text into manageable units for further analysis and processing. By breaking down text into tokens, machines can understand and interpret human language, enabling a wide range of language processing applications.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3657b92a",
   "metadata": {},
   "source": [
    "## Using Chat GPT using Python\n",
    "\n",
    "Below we will practice by seting up a prompt for ChatGPT and send a query via the OpenAI API to return a response, you can follow these steps using the OpenAI Python library:\n",
    "\n",
    "Note. At this point you will need your OpenAI account and the Key we asked you to create. [Here are instructions to create an OpenAI key](https://platform.openai.com/docs/quickstart?context=python).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc1aa4d",
   "metadata": {},
   "source": [
    "First we will install the OpenAI Python library, this library will help us communicate with ChatGPT via API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f56641",
   "metadata": {},
   "source": [
    "After that, we will set up our OpenAI key. This key will allow our computer to access ChatGPT. It is a unique key that hsould NOT be shared online, for example it should not be shared on GitHub. (You will need to remember to remove the Key from the notebook every time you push changes to GitHub and then put it back into the notebook when in need. So, save it out!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563d3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = #'use-your-API-key-here'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c80ed7b",
   "metadata": {},
   "source": [
    "Note. Replace 'your-api-key' with your actual API key obtained from OpenAI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4267319a",
   "metadata": {},
   "source": [
    "After setting up OpenAI, we will define a function to send a query to ChatGPT and get a response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec38864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inside the quotes (\"\") place the task you want the model to do, just like you would in ChatGPT.\n",
    "Task = \"How are you doing?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03b64af",
   "metadata": {},
   "source": [
    "We will then write a prompt and send an API query to ChatGPT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c88f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = openai.api_key)\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo-preview\", # choose model\n",
    "    messages=[{\"role\": \"user\", \"content\": Task }],\n",
    "    stream=False,\n",
    "    temperature= 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9be7c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_response = stream.choices[0].message.content\n",
    "print(AI_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b22be3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Let's analyze the code above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0866edce",
   "metadata": {},
   "source": [
    "First, we have defined a `Task` this is the question a human is asking. The variable name `Task` is somehow arbitrary, we could have called it `Query` perhaps that would have been more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce09de05",
   "metadata": {},
   "source": [
    "After importing the OpenAI library, we open a `client`. A `client` for the ChatGPT API is the application running on your computer that interacts with the API of ChatGPT running on the servers of OpenAI. The `client` sends queries and receives responses. The client acts as an intermediary between the user and the ChatGPT system, the model hosted by OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0cf056",
   "metadata": {},
   "source": [
    "The `client` gets initialized and for that it requires a `model` we use `gpt-4` as model, some of the students had problems using that model but where succesful in using `gpt-4-turbo-preview`, try changing the model if you see the code above failing. You can find the models you have access to on this page: https://platform.openai.com/account/limits\n",
    "\n",
    "\n",
    "The `client` also needs a `temperature` to be set. `Temperature` is used to create the randomness in the response, the higher the temperature the more diverse will be the answer to the same question when repeated. In other words, with temperature set to `0` the model will respond providing always the same to the same question. With higher temperature the answers will vary every time the code is run, and some of them might be actually be more useful than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce0d19",
   "metadata": {},
   "source": [
    "The `messages` contain the syntax to define what it is being asked and later on what is the `role` of the `system`. In this case, we onl have one `role` which is that of a `user`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4e79b",
   "metadata": {},
   "source": [
    "The `Task` (the `Query`) is the content we provided for the `user`. ChatGPT returned a `stream` containing `chunks`. \n",
    "\n",
    "The `stream` refers to a continuous or real-time connection established between a client application and the ChatGPT model hosted by OpenAI. Streaming enables the client to send multiple queries to the model over time and receive corresponding responses without the need to establish a new connection for each query.\n",
    "\n",
    "The `chunks` instead typically refer to segments or portions of text that are processed or generated by the model in smaller units rather than as a single continuous sequence. Chunks are often used to break down longer pieces of text into more manageable segments for processing or analysis. The text inside `chunks` can vary depending on the requirements of the application or task. For example, text may be chunked based on a fixed length (e.g., dividing text into chunks of 100 tokens each) or based on natural language boundaries (e.g., splitting text into sentences or paragraphs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd18c56a",
   "metadata": {},
   "source": [
    "Finally, we have seen that the ChatGPT API return the response into an object `stream.choices[0].message.content`. We take the response and print it out. Note that the response is deeply nested inside the object, and we need to navigate to get to its `content`. For the time being we will not discuss further these topic, but there other ways to get the response out of the AI system. We might see those in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c895d96",
   "metadata": {},
   "source": [
    "### ChatGPT and roles\n",
    "\n",
    "ChatGPT uses roles to identify the actors in a chat. The user (the human) and the system (the AI) are the two actors. This architeture allows building interactive chats that can be used to respond to multiple questions and that use the model saved in ChatGPT (basically that uses what ChatGPT has learned from all the text humans have put online) to respond. \n",
    "\n",
    "The example function uses the two roles `user` and `system` to build a chat that given a question return an asnwer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = openai.api_key)\n",
    "\n",
    "messages = [ {\"role\": \"system\", \"content\":  \n",
    "              \"You are a intelligent assistant.\"} ] \n",
    "while True: \n",
    "    message = input(\"User : \") \n",
    "    if message: \n",
    "        messages.append( \n",
    "            {\"role\": \"user\", \"content\": message}, \n",
    "        ) \n",
    "        \n",
    "        chat = client.chat.completions.create( \n",
    "            model=\"gpt-3.5-turbo\", messages=messages \n",
    "        ) \n",
    "    reply = chat.choices[0].message.content \n",
    "    print(f\"ChatGPT: {reply}\") \n",
    "    messages.append({\"role\": \"assistant\", \"content\": reply}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58ef1a8",
   "metadata": {},
   "source": [
    "The previous code implements a simple chat interface for ChatGPT in Python. This is not quite as advanced as the one availble at [chat.openai](https://chat.openai.com/) but still uite interesting.\n",
    "\n",
    "As you can see in the code we set a `role` for the `system` by providing a `prompt`. The `prompt` in this case is \"You are a intelligent assistant.\" The `role` of the `user` is then captured via messages inputted into a a text box. These messages change every time you use the chat.\n",
    "\n",
    "This is a general architecture, the `system` and the `user` work together by communicating messages. The `role` of the `system` is often referred to as `prompt` and `prompt` engineering is predicted to be a major future goal of data scientists. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591fcd48",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Your goal is to reuse the code above but create a chat assistant that is specialized on Python code. In other words, copy and paste the code in the last cell and change a section of the code so as to specialize the expertise of the Chat Assistant to coding in Python.\n",
    "\n",
    "Please, do not get fooled, this is a simple request. As we explained above `prompt` engineering is key to tuning how a chat assistant works and what it does. We are asking for you to practice with some prompt engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804658a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aca858bc",
   "metadata": {},
   "source": [
    "### Wrap up and conclusions\n",
    "\n",
    "This tutorial took us on a journey on AI. We covered multiple foundational concepts and provided simple examples of code that introduces basic functionality of the latest AI models, specifically ChatGPT. \n",
    "\n",
    "The field of AI is fast growing. It is likely to become key to data science in the near future. Tools like ChatGPT, can help speed up drafting intial code, reports and text, yet, they are not to be trusted because we understand that they can return false or incorrect information. Humans are needed to make sure the Queries, and Prompts are properly set up and the outputs are properly delivered and validated.\n",
    "\n",
    "As the pace at which the AI models and APIs are being developed accelerates, the code oresented here is likely to change but some of the fundamental concepts is likely to stay and provide a good foundations for your future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f5111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
