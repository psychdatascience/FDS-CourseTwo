{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6251f86d",
   "metadata": {},
   "source": [
    "# üß† Talking to Machines: A Gentle Introduction to Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab91144",
   "metadata": {},
   "source": [
    "\n",
    "Large Language Models (LLMs) are powerful tools that understand and generate human language. They're trained on vast amounts of text and can respond to prompts in natural and intelligent ways. In this tutorial, you'll learn how to interact with ChatGPT using Python, build simple behavioral science simulations, and visualize the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e02bcb1",
   "metadata": {},
   "source": [
    "\n",
    "## üîë Before We Begin: What Is an OpenAI API Key?\n",
    "\n",
    "Before we can talk to ChatGPT from Python, we need a pass called an **API key**. Think of it like your student ID‚Äîit tells OpenAI who you are and what you‚Äôre allowed to do.\n",
    "\n",
    "### üéì How to Get Your API Key\n",
    "\n",
    "1. Create an OpenAI account: [https://platform.openai.com/signup](https://platform.openai.com/signup)\n",
    "2. Visit the API Keys page: [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)\n",
    "3. Click *\"Create new secret key\"* and copy it\n",
    "\n",
    "üîí **Never share your API key publicly.**\n",
    "\n",
    "üìö Official Docs:\n",
    "- [Quickstart Guide](https://platform.openai.com/docs/quickstart)\n",
    "- [Python Library Reference](https://platform.openai.com/docs/libraries/python)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c4dfc",
   "metadata": {},
   "source": [
    "## üß± 1. The Foundation: Language Models Learn Like Children Do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f9f6ea",
   "metadata": {},
   "source": [
    "\n",
    "Think of an LLM like a child learning to speak by listening. Over time, the more language it hears, the better it gets at predicting what word comes next.\n",
    "\n",
    "### ‚ñ∂Ô∏è Example 1: Asking ChatGPT a Psychology Question\n",
    "**Goal:** Learn how to make a basic request to ChatGPT using Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4537b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"your-api-key\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful psychology tutor.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain Pavlov's dog experiment in simple terms.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19544aea",
   "metadata": {},
   "source": [
    "## üß† 2. Prompt Engineering: Giving the Model the Right Clues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f570ba",
   "metadata": {},
   "source": [
    "\n",
    "Prompts guide the model‚Äôs behavior‚Äîlike gestures in charades. The same question can yield very different answers depending on the prompt's context.\n",
    "\n",
    "### ‚ñ∂Ô∏è Example 2: Changing the Prompt Changes the Answer\n",
    "**Goal:** Show how changing the prompt style alters the model's output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d036ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "roles = [\"You are a kind therapist.\", \"You are a strict cognitive psychologist.\", \"You are a curious child.\"]\n",
    "\n",
    "for role in roles:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": role},\n",
    "            {\"role\": \"user\", \"content\": \"What is cognitive dissonance?\"}\n",
    "        ]\n",
    "    )\n",
    "    print(f\"\\n{role}\\n{'-'*len(role)}\\n{response['choices'][0]['message']['content']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bdce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "roles = [\"Therapist\", \"Psychologist\", \"Child\"]\n",
    "word_counts = [112, 148, 45]  # Hypothetical counts\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(roles, word_counts)\n",
    "plt.title(\"Word Count by Prompt Role\")\n",
    "plt.ylabel(\"Number of Words\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b39735",
   "metadata": {},
   "source": [
    "## üß† 3. Behavioral Data Meets LLMs: Automating Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8b0cdc",
   "metadata": {},
   "source": [
    "\n",
    "LLMs can help summarize large amounts of open-ended behavioral data‚Äîjust like coding responses by hand, but faster.\n",
    "\n",
    "### ‚ñ∂Ô∏è Example 3: Summarizing Open-Ended Responses\n",
    "**Goal:** Use the model to generate summaries from raw behavioral responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2301a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "responses = [\n",
    "    \"I felt anxious at a party because I didn‚Äôt know anyone.\",\n",
    "    \"During a group presentation, I was sweating and couldn't speak well.\",\n",
    "    \"Being at a networking event made me panic and want to leave.\"\n",
    "]\n",
    "\n",
    "summaries = []\n",
    "for r in responses:\n",
    "    reply = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a psychology researcher summarizing data.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Summarize this response: {r}\"}\n",
    "        ]\n",
    "    )\n",
    "    summaries.append(reply['choices'][0]['message']['content'])\n",
    "\n",
    "print(\"\\n\".join(summaries))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b981fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "text = \" \".join(summaries)\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Summary Word Cloud of Social Anxiety Descriptions\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a70416",
   "metadata": {},
   "source": [
    "## üß† 4. Measuring the Mind: Turning Prompts into Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f25e94",
   "metadata": {},
   "source": [
    "\n",
    "You can simulate psychological experiments using prompts. Here we model responses to the trolley problem under different emotions.\n",
    "\n",
    "### ‚ñ∂Ô∏è Example 4: Simulated Moral Reasoning\n",
    "**Goal:** Simulate responses to the trolley problem under different emotional conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda7fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contexts = [\"You are calm and logical.\", \"You are anxious and panicking.\", \"You are deeply empathetic.\"]\n",
    "\n",
    "for context in contexts:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": context},\n",
    "            {\"role\": \"user\", \"content\": \"A trolley is about to kill five people. Do you pull the lever to divert it, killing one person instead?\"}\n",
    "        ]\n",
    "    )\n",
    "    print(f\"\\n{context}\\n{'-'*len(context)}\\n{response['choices'][0]['message']['content']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b96c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contexts = [\"Logical\", \"Anxious\", \"Empathetic\"]\n",
    "choices = [1, 0, 1]  # Hypothetical binary outcomes\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(contexts, choices)\n",
    "plt.title(\"Lever Choice by Simulated Emotional Context\")\n",
    "plt.ylabel(\"Decision (1=Pull Lever, 0=Don‚Äôt)\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9ae3d1",
   "metadata": {},
   "source": [
    "## üéì Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a193a",
   "metadata": {},
   "source": [
    "\n",
    "LLMs like ChatGPT can become powerful tools for behavioral scientists. They allow us to generate, explore, and simulate human behavior in new and scalable ways‚Äîwith just a few lines of Python.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}